{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XSFYNYnEWD3y",
    "outputId": "b6673c80-78a0-49b5-c65a-548212af7dab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8409 entries, 0 to 8408\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         8409 non-null   int64 \n",
      " 1   tweet      8409 non-null   object\n",
      " 2   emotion    8409 non-null   object\n",
      " 3   offensive  8409 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 262.9+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv('../data/emoevent_es.csv', sep='\\t')\n",
    "\n",
    "df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dtale\n",
    "\n",
    "# Mostrar el DataFrame en D-Tale\n",
    "# d = dtale.show(df)\n",
    "# d.open_browser() \n",
    "# d._main_url\n",
    "# dtale.utils.get_open_dtales() \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "22jmr_M5W-n4"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"id\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "1LVTtvGDrqpV",
    "outputId": "ce166545-09f1-47cf-a2b4-73860bb2b59e"
   },
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Gm2unaVFoxaP"
   },
   "outputs": [],
   "source": [
    "# Contar las emociones ofensivas\n",
    "offensive_emotion_counts = df[df['offensive'] == 1]['emotion'].value_counts()\n",
    "\n",
    "# Convertir a DataFrame para visualización\n",
    "offensive_emotion_counts_df = offensive_emotion_counts.reset_index()\n",
    "offensive_emotion_counts_df.columns = ['emotion', 'offensive_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "others      4127\n",
       "joy         1815\n",
       "sadness     1009\n",
       "anger        857\n",
       "surprise     344\n",
       "disgust      161\n",
       "fear          96\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "-oPuyJMWrkK0",
    "outputId": "67bfeeb4-e937-45b2-a72b-8b26399745c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>offensive_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>others</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>joy</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surprise</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sadness</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fear</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    emotion  offensive_count\n",
       "0     anger              378\n",
       "1    others              111\n",
       "2   disgust               94\n",
       "3       joy               72\n",
       "4  surprise               37\n",
       "5   sadness               10\n",
       "6      fear                4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offensive_emotion_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Gc9A7adnXb5f"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"offensive\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TJhpNVTaXIR6"
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'tweet': 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "xut8mgsfXpyh",
    "outputId": "f07d30da-5309-4d09-a0ba-bd5add6e46fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, emotion]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas_repetidas = df[df.duplicated()]\n",
    "filas_repetidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q2t3lQlUXxUE",
    "outputId": "cba267d5-69c6-4f02-8cd4-622954e1d4c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "others      4127\n",
      "joy         1815\n",
      "sadness     1009\n",
      "anger        857\n",
      "surprise     344\n",
      "disgust      161\n",
      "fear          96\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "emotion_distribution = df['emotion'].value_counts()\n",
    "\n",
    "# Mostrar la distribución\n",
    "print(emotion_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "others     4127\n",
      "joy        1815\n",
      "sadness    1009\n",
      "anger       857\n",
      "disgust     161\n",
      "fear         96\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Eliminar las filas donde emotion sea 'surprise'\n",
    "df = df[df[\"emotion\"] != \"surprise\"].copy()\n",
    "\n",
    "# Verificamos que ya no esté 'surprise' en la distribución\n",
    "print(df[\"emotion\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "HdVnZZ7oX37e",
    "outputId": "4a3654d2-230d-4c2d-e86a-bd1851d2bbd7"
   },
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "EjqC0Ay-Zcmo"
   },
   "outputs": [],
   "source": [
    "# Mapeo de etiquetas de inglés a español\n",
    "emotion_mapping = {\n",
    "    'others': 'neutral',#segun indica la página oficial https://competitions.codalab.org/competitions/28682\n",
    "    'anger': 'ira',\n",
    "    'disgust': 'disgusto',\n",
    "    'sadness': 'tristeza',\n",
    "    'joy': 'alegría',\n",
    "    'fear': 'miedo',\n",
    "    # 'surprise': 'sorpresa'\n",
    "}\n",
    "\n",
    "df['emotion'] = df['emotion'].map(emotion_mapping) # columna 'emotion' con valores en español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WIISuq-ZZnxK",
    "outputId": "097bbd6c-5c6e-4f4e-ba6a-a4e2437613eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "neutral     4127\n",
      "alegría     1815\n",
      "tristeza    1009\n",
      "ira          857\n",
      "disgusto     161\n",
      "miedo         96\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['emotion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "neutral     4127\n",
      "alegría     1815\n",
      "tristeza    1009\n",
      "ira          857\n",
      "disgusto     161\n",
      "miedo         96\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['emotion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "2fIYEhjEaD5y",
    "outputId": "8d04aec6-bd5e-46f1-f62b-cfe75e95e693"
   },
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_before</th>\n",
       "      <th>word_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acabo de ver la gran pérdida que estamos tenie...</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USER ¿A que vamos a reconstruir Notre Dame ant...</td>\n",
       "      <td>None</td>\n",
       "      <td>URL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desde ayer andan sufriendo por el incendio de ...</td>\n",
       "      <td>de</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muy afectada -como muchísima gente- por lo ocu...</td>\n",
       "      <td>a</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es una mierda lo que paso en HASHTAG pero plea...</td>\n",
       "      <td>en</td>\n",
       "      <td>pero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8404</th>\n",
       "      <td>Dembele es un imbécil, neta es increíble lo pe...</td>\n",
       "      <td>None</td>\n",
       "      <td>HASHTAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8405</th>\n",
       "      <td>HASHTAG Puta q son desagradables los wnes del ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Puta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8406</th>\n",
       "      <td>Puta que me cae mal Suárez ctm HASHTAG</td>\n",
       "      <td>ctm</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8407</th>\n",
       "      <td>Como te odio USER, odio tus comentarios filosó...</td>\n",
       "      <td>None</td>\n",
       "      <td>HASHTAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8408</th>\n",
       "      <td>Miedo me da que mi país esté en manos de perso...</td>\n",
       "      <td>None</td>\n",
       "      <td>HASHTAG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8043 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text word_before word_after\n",
       "0     Acabo de ver la gran pérdida que estamos tenie...          en       None\n",
       "1     USER ¿A que vamos a reconstruir Notre Dame ant...        None        URL\n",
       "2     Desde ayer andan sufriendo por el incendio de ...          de          y\n",
       "3     Muy afectada -como muchísima gente- por lo ocu...           a       None\n",
       "4     Es una mierda lo que paso en HASHTAG pero plea...          en       pero\n",
       "...                                                 ...         ...        ...\n",
       "8404  Dembele es un imbécil, neta es increíble lo pe...        None    HASHTAG\n",
       "8405  HASHTAG Puta q son desagradables los wnes del ...        None       Puta\n",
       "8406             Puta que me cae mal Suárez ctm HASHTAG         ctm       None\n",
       "8407  Como te odio USER, odio tus comentarios filosó...        None    HASHTAG\n",
       "8408  Miedo me da que mi país esté en manos de perso...        None    HASHTAG\n",
       "\n",
       "[8043 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def get_words_around_hashtag(text):\n",
    "    # Patrón para encontrar palabra antes y después de HASHTAG\n",
    "    match = re.search(r'(\\w+)?\\s*HASHTAG\\s*(\\w+)?', text)\n",
    "    if match:\n",
    "        return match.group(1), match.group(2)\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Aplicamos la función a cada tweet\n",
    "df[['word_before', 'word_after']] = df['text'].apply(lambda x: pd.Series(get_words_around_hashtag(str(x))))\n",
    "# Filtrar los que tienen HASHTAG\n",
    "df_hashtag = df[df['text'].str.contains(\"HASHTAG\", na=False)]\n",
    "\n",
    "# Mostrar los resultados\n",
    "df_hashtag[['text', 'word_before', 'word_after']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar y filtrar palabras antes de HASHTAG con frecuencia > 1\n",
    "before_common = df['word_before'].value_counts()\n",
    "before_common = before_common[before_common > 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_after\n",
      "HASHTAG       2291\n",
      "URL            561\n",
      "y              223\n",
      "en             120\n",
      "es             117\n",
      "              ... \n",
      "qué              3\n",
      "cada             3\n",
      "eres             3\n",
      "creo             3\n",
      "celebramos       3\n",
      "Name: count, Length: 121, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contar y filtrar palabras después de HASHTAG con frecuencia > 1\n",
    "after_common = df['word_after'].value_counts()\n",
    "after_common = after_common[after_common > 2]\n",
    "print(after_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a DataFrame si quieres trabajar con ellas\n",
    "before_df = before_common.reset_index()\n",
    "before_df.columns = ['word_before', 'frequency']\n",
    "\n",
    "after_df = after_common.reset_index()\n",
    "after_df.columns = ['word_after', 'frequency']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "orzkd0rPaAiw"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    tweet = re.sub(r'  ', ' ', tweet)\n",
    "    tweet = re.sub(r'@USER', ' ', tweet)\n",
    "    tweet = re.sub(r'USER', ' ', tweet)\n",
    "    tweet = re.sub(r'DE HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r'En HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r'El HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r'La HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' del HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' de HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' por HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' en HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' el HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' las HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' a los HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' los HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' al HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' la HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' la HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' ni HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' e HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' a HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' o HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' es HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' con HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' como HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' para HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' y HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' Este HASHTAG,', ' ', tweet)\n",
    "    tweet = re.sub(r'HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' y URL', ' ', tweet)\n",
    "    tweet = re.sub(r'URL', ' ', tweet)\n",
    "    tweet = re.sub(r'l@s', 'los', tweet)\n",
    "    tweet = re.sub(r'L@s', 'los', tweet)\n",
    "    tweet = re.sub(r'tod@s', 'todos', tweet)\n",
    "    tweet = re.sub(r'Tod@s', 'todos', tweet)\n",
    "    tweet = re.sub(r'est@s', 'estos', tweet)\n",
    "    tweet = re.sub(r'alumn@s', 'alumnos', tweet)\n",
    "    tweet = re.sub(r'hij@s', 'hijos', tweet)\n",
    "    tweet = re.sub(r'niñ@s', 'niños', tweet)\n",
    "    tweet = re.sub(r'nosotr@s', 'nosotros', tweet)\n",
    "    tweet = re.sub(r'compañer@s', 'compañeros', tweet)\n",
    "    tweet = re.sub(r'católic@s', 'católicos', tweet)\n",
    "    tweet = re.sub(r'http\\S+|www.\\S+', ' ', tweet)  # eliminar urls\n",
    "    # tweet = re.sub(r'[^a-zA-ZñÑáéíóúÁÉÍÓÚ\\s]', '', tweet)  # eliminar símbolos\n",
    "    # tweet = tweet.lower()\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet).strip()  # eliminar espacios extras\n",
    "    return tweet\n",
    "\n",
    "df['text'] = df['text'].apply(clean_tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Unir todos los textos en uno solo\n",
    "all_text = ' '.join(df['text'].astype(str))\n",
    "\n",
    "# Contar cada caracter\n",
    "char_counts = Counter(all_text)\n",
    "\n",
    "# Mostrar los caracteres y sus conteos ordenados por frecuencia\n",
    "# for char, count in char_counts.most_common():\n",
    "#     print(f\"'{char}': {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Paso 1: eliminar texto entre corchetes\n",
    "df['text'] = df['text'].astype(str).str.replace(r'\\[.*?\\]', '', regex=True)\n",
    "\n",
    "# Paso 2: listar palabras que contienen @\n",
    "palabras_con_arroba = df['text'].str.findall(r'\\S*@\\S+')\n",
    "\n",
    "# Paso 3: eliminar palabras que contienen @\n",
    "df['text'] = df['text'].str.replace(r'\\S*@\\S+', '', regex=True)\n",
    "\n",
    "# Paso 4: corregir acentos mal escritos\n",
    "df['text'] = (\n",
    "    df['text']\n",
    "    .str.replace('à', 'á')\n",
    "    .str.replace('è', 'é')\n",
    "    .str.replace('ì', 'í')\n",
    "    .str.replace('ò', 'ó')\n",
    "    .str.replace('ù', 'ú')\n",
    "    .str.replace('À', 'Á')\n",
    "    .str.replace('È', 'É')\n",
    "    .str.replace('Ì', 'Í')\n",
    "    .str.replace('Ò', 'Ó')\n",
    "    .str.replace('Ù', 'Ú')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dtale\n",
    "\n",
    "# Mostrar el DataFrame en D-Tale\n",
    "d = dtale.show(palabras_con_arroba)\n",
    "d.open_browser() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' ': 156960\n",
      "'e': 83905\n",
      "'a': 75521\n",
      "'o': 59076\n",
      "'s': 47587\n",
      "'n': 43077\n",
      "'r': 40986\n",
      "'i': 36949\n",
      "'l': 35572\n",
      "'d': 30443\n",
      "'t': 27693\n",
      "'u': 26774\n",
      "'c': 23061\n",
      "'m': 18537\n",
      "'p': 15787\n",
      "'.': 10136\n",
      "'b': 7488\n",
      "'g': 7339\n",
      "'q': 7269\n",
      "'v': 7079\n",
      "'h': 6715\n",
      "'y': 6680\n",
      "',': 5574\n",
      "'f': 4159\n",
      "'E': 4112\n",
      "'í': 3509\n",
      "'á': 3285\n",
      "'ó': 3168\n",
      "'A': 3045\n",
      "'j': 2922\n",
      "'L': 2596\n",
      "'!': 2462\n",
      "'z': 2461\n",
      "'S': 2286\n",
      "'C': 2070\n",
      "'M': 2041\n",
      "'N': 1987\n",
      "'O': 1957\n",
      "'é': 1935\n",
      "'P': 1817\n",
      "'D': 1588\n",
      "'ñ': 1539\n",
      "'T': 1351\n",
      "'R': 1314\n",
      "'I': 1198\n",
      "'?': 1046\n",
      "'U': 1009\n",
      "'V': 916\n",
      "'H': 848\n",
      "'B': 819\n",
      "'x': 772\n",
      "'Q': 768\n",
      "'ú': 735\n",
      "'G': 735\n",
      "'F': 662\n",
      "'Y': 641\n",
      "'¡': 532\n",
      "'¿': 507\n",
      "'️': 499\n",
      "'J': 403\n",
      "'k': 168\n",
      "'❤': 152\n",
      "'😂': 132\n",
      "'w': 104\n",
      "'ç': 96\n",
      "'😭': 90\n",
      "';': 89\n",
      "'X': 87\n",
      "'Z': 86\n",
      "'😢': 76\n",
      "'😍': 75\n",
      "'É': 74\n",
      "'Ó': 73\n",
      "'🙏': 68\n",
      "'Í': 68\n",
      "'💪': 65\n",
      "'🤔': 63\n",
      "'😱': 59\n",
      "'Ñ': 57\n",
      "'Á': 53\n",
      "'ü': 52\n",
      "'K': 45\n",
      "'W': 40\n",
      "'😔': 37\n",
      "'😉': 31\n",
      "'😜': 29\n",
      "'😎': 26\n",
      "'😊': 25\n",
      "'Ú': 20\n",
      "'🤩': 17\n",
      "'😥': 14\n",
      "'🤗': 14\n",
      "'😓': 11\n",
      "'😘': 11\n",
      "'😅': 11\n",
      "'🥰': 10\n",
      "'😰': 9\n",
      "'Ç': 9\n",
      "'🙈': 8\n",
      "'😖': 8\n",
      "'🥺': 7\n",
      "'😨': 6\n",
      "'😡': 5\n",
      "'🤬': 5\n",
      "'😩': 5\n",
      "'🙊': 4\n",
      "'🙂': 3\n",
      "'🙀': 2\n",
      "'😤': 2\n",
      "'🙉': 2\n",
      "'Ü': 2\n",
      "'😿': 1\n",
      "'🙃': 1\n",
      "'😇': 1\n"
     ]
    }
   ],
   "source": [
    "# def limpiar_texto(texto):\n",
    "#     # Elimina todo lo que no esté en el conjunto permitido\n",
    "#     return ''.join(re.findall(caracteres_permitidos, texto))\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    # Reemplaza caracteres no permitidos por espacio\n",
    "    return ''.join(c if re.match(caracteres_permitidos, c) else ' ' for c in texto)\n",
    "\n",
    "# Letras latinas con tildes y ñ\n",
    "letras = 'a-zA-ZáéíóúÁÉÍÓÚñÑüÜçÇ'\n",
    "\n",
    "# Dígitos\n",
    "digitos = '0-9'\n",
    "\n",
    "# Signos de puntuación básicos\n",
    "# puntuacion = r\"\\.\\,\\!\\¡\\?\\¿\\:;\\\"\\'\\-\\(\\)\"\n",
    "puntuacion = r'\\.\\,\\!\\¡\\?\\¿\\;'\n",
    "\n",
    "# Emojis de emociones: puedes ampliarlos si usas más\n",
    "emojis = '❤️😂😭😱😢😍😔🤔🙏💪😜😎😊😡🤬🤗🤩😅😉😘🥰😇🙂🙃🥺😖😤😨😩😰😓😥😿😾😼🙀🙈🙉🙊'\n",
    "\n",
    "# Todos juntos\n",
    "caracteres_permitidos = f\"[{letras}{puntuacion}{emojis} ]\" #{digitos}\n",
    "\n",
    "df['text_limpio'] = df['text'].astype(str).apply(limpiar_texto)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "contador = Counter(''.join(df['text_limpio']))\n",
    "for char, count in contador.most_common():\n",
    "    print(f\"'{char}': {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gui3 = show(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text_limpio']\n",
    "df = df.drop(columns=[\"word_before\", \"word_after\", \"text_limpio\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Función para limpiar texto\n",
    "def limpiar_texto(texto):\n",
    "    texto = str(texto)  # Por si hay NaNs u objetos raros\n",
    "    texto = texto.strip()  # Eliminar espacios al principio y al final\n",
    "    texto = re.sub(r'\\s+', ' ', texto)  # Reemplaza múltiples espacios por uno\n",
    "    return texto\n",
    "\n",
    "# Limpiar textos\n",
    "df[\"text\"] = df[\"text\"].apply(limpiar_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar puntos y comas al inicio del texto\n",
    "df['text'] = df['text'].str.replace(r'^[.,]+', '', regex=True).str.lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fasttext-wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc9cbe3d3fa4bbf845f5d925b2a224a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Detectando idiomas (sensitivo):   0%|          | 0/8065 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de idiomas detectados:\n",
      "idioma\n",
      "spa_Latn          7579\n",
      "low_confidence     330\n",
      "yue_Hant            74\n",
      "kor_Hang            35\n",
      "glg_Latn             9\n",
      "ast_Latn             8\n",
      "por_Latn             8\n",
      "ita_Latn             4\n",
      "cat_Latn             4\n",
      "epo_Latn             3\n",
      "fra_Latn             2\n",
      "lmo_Latn             1\n",
      "hun_Latn             1\n",
      "deu_Latn             1\n",
      "tsn_Latn             1\n",
      "gaz_Latn             1\n",
      "ces_Latn             1\n",
      "vec_Latn             1\n",
      "pap_Latn             1\n",
      "oci_Latn             1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>idioma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acabo de ver la gran pérdida que estamos tenie...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¿A que vamos a reconstruir Notre Dame antes de...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desde ayer andan sufriendo por el incendio y n...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muy afectada como muchísima gente por lo ocurr...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es una mierda lo que paso pero please dejen de...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    idioma\n",
       "0  Acabo de ver la gran pérdida que estamos tenie...  spa_Latn\n",
       "1  ¿A que vamos a reconstruir Notre Dame antes de...  spa_Latn\n",
       "2  Desde ayer andan sufriendo por el incendio y n...  spa_Latn\n",
       "3  Muy afectada como muchísima gente por lo ocurr...  spa_Latn\n",
       "4  Es una mierda lo que paso pero please dejen de...  spa_Latn"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "\n",
    "# Cargar modelo fastText entrenado para identificación de idiomas\n",
    "model_path = r\"C:\\Users\\leo23\\OneDrive\\Documentos\\Fine_tuning_llama2\\models\\fasttext\\models--facebook--fasttext-language-identification\\snapshots\\3af127d4124fc58b75666f3594bb5143b9757e78\\model.bin\"\n",
    "language_detector = fasttext.load_model(model_path)\n",
    "\n",
    "# Función mejorada para preprocesar y detectar idioma\n",
    "def detect_language(text: str, threshold: float = 0.75) -> str:\n",
    "    try:\n",
    "        if pd.isna(text) or len(text.strip()) < 3:\n",
    "            return \"unknown\"\n",
    "        \n",
    "        # Limpieza del texto\n",
    "        clean_text = re.sub(r'[^\\w\\s]', '', text).strip().replace(\"\\n\", \" \")\n",
    "        \n",
    "        # Obtener las 3 predicciones más probables\n",
    "        labels, probabilities = language_detector.predict(clean_text, k=3)\n",
    "        \n",
    "        if probabilities[0] < threshold:\n",
    "            return \"low_confidence\"\n",
    "        \n",
    "        return labels[0].split(\"__\")[-1]\n",
    "    except Exception as e:\n",
    "        return \"error\"\n",
    "\n",
    "# Aplicar detección con progreso\n",
    "tqdm.pandas(desc=\"Detectando idiomas (sensitivo)\")\n",
    "df[\"idioma\"] = df[\"text\"].progress_apply(detect_language)\n",
    "\n",
    "# Guardar resultados\n",
    "df.to_csv(\"../data/Emoevent_dataset_con_idioma.csv\", index=False)\n",
    "\n",
    "# Mostrar ejemplo\n",
    "print(\"Distribución de idiomas detectados:\")\n",
    "print(df[\"idioma\"].value_counts())\n",
    "\n",
    "df[[\"text\", \"idioma\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fasttext\n",
    "# from huggingface_hub import hf_hub_download\n",
    "# import fasttext\n",
    "# import pandas as pd\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# # Ruta al modelo (usa la ruta completa de tu sistema)\n",
    "# model_path = r\"C:\\Users\\leo23\\OneDrive\\Documentos\\Fine_tuning_llama2\\models\\fasttext\\models--facebook--fasttext-language-identification\\snapshots\\3af127d4124fc58b75666f3594bb5143b9757e78\\model.bin\"\n",
    "\n",
    "# # Cargar el modelo\n",
    "# language_detector = fasttext.load_model(model_path)\n",
    "\n",
    "# # 2. Función para detectar idioma con manejo de errores\n",
    "# def detect_language(text: str) -> str:\n",
    "#     try:\n",
    "#         if pd.isna(text) or len(text.strip()) < 3:  # Manejar textos vacíos/cortos\n",
    "#             return \"unknown\"\n",
    "#         predictions = language_detector.predict(text.replace(\"\\n\", \" \"), k=1)\n",
    "#         return predictions[0][0].split(\"__\")[-1]\n",
    "#     except:\n",
    "#         return \"error\"\n",
    "\n",
    "# # 3. Aplicar detección a todo el DataFrame con barra de progreso\n",
    "# tqdm.pandas(desc=\"Detectando idiomas\")\n",
    "# df[\"idioma\"] = df[\"text\"].progress_apply(detect_language)\n",
    "\n",
    "# # 4. Analizar resultados\n",
    "# print(\"Conteo de idiomas identificados:\")\n",
    "# df[\"idioma\"].value_counts()\n",
    "\n",
    "# # Guarda el resultado en un nuevo archivo CSV\n",
    "# df.to_csv(\"../data/Emoevent_dataset_con_idioma.csv\", index=False)\n",
    "\n",
    "# # Muestra los primeros ejemplos para verificar\n",
    "# df[[\"text\", \"idioma\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de idiomas identificados:\n",
      "idioma\n",
      "spa_Latn          7579\n",
      "low_confidence     330\n",
      "yue_Hant            74\n",
      "kor_Hang            35\n",
      "glg_Latn             9\n",
      "ast_Latn             8\n",
      "por_Latn             8\n",
      "ita_Latn             4\n",
      "cat_Latn             4\n",
      "epo_Latn             3\n",
      "fra_Latn             2\n",
      "lmo_Latn             1\n",
      "hun_Latn             1\n",
      "deu_Latn             1\n",
      "tsn_Latn             1\n",
      "gaz_Latn             1\n",
      "ces_Latn             1\n",
      "vec_Latn             1\n",
      "pap_Latn             1\n",
      "oci_Latn             1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>idioma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acabo de ver la gran pérdida que estamos tenie...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¿A que vamos a reconstruir Notre Dame antes de...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desde ayer andan sufriendo por el incendio y n...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muy afectada como muchísima gente por lo ocurr...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es una mierda lo que paso pero please dejen de...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8404</th>\n",
       "      <td>Dembele es un imbécil, neta es increíble lo pe...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8405</th>\n",
       "      <td>Puta q son desagradables los wnes del Barca en...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8406</th>\n",
       "      <td>Puta que me cae mal Suárez ctm</td>\n",
       "      <td>low_confidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8407</th>\n",
       "      <td>Como te odio , odio tus comentarios filosófico...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8408</th>\n",
       "      <td>Miedo me da que mi país esté en manos de perso...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8065 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text          idioma\n",
       "0     Acabo de ver la gran pérdida que estamos tenie...        spa_Latn\n",
       "1     ¿A que vamos a reconstruir Notre Dame antes de...        spa_Latn\n",
       "2     Desde ayer andan sufriendo por el incendio y n...        spa_Latn\n",
       "3     Muy afectada como muchísima gente por lo ocurr...        spa_Latn\n",
       "4     Es una mierda lo que paso pero please dejen de...        spa_Latn\n",
       "...                                                 ...             ...\n",
       "8404  Dembele es un imbécil, neta es increíble lo pe...        spa_Latn\n",
       "8405  Puta q son desagradables los wnes del Barca en...        spa_Latn\n",
       "8406                     Puta que me cae mal Suárez ctm  low_confidence\n",
       "8407  Como te odio , odio tus comentarios filosófico...        spa_Latn\n",
       "8408  Miedo me da que mi país esté en manos de perso...        spa_Latn\n",
       "\n",
       "[8065 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Contar la cantidad de ocurrencias por cada idioma\n",
    "conteo_idiomas = df[\"idioma\"].value_counts()\n",
    "print(\"Conteo de idiomas identificados:\")\n",
    "print(conteo_idiomas)\n",
    "\n",
    "# Muestra los primeros registros del dataset con la columna \"idioma\"\n",
    "display(df[[\"text\", \"idioma\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>idioma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acabo de ver la gran pérdida que estamos tenie...</td>\n",
       "      <td>tristeza</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¿A que vamos a reconstruir Notre Dame antes de...</td>\n",
       "      <td>tristeza</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desde ayer andan sufriendo por el incendio y n...</td>\n",
       "      <td>ira</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muy afectada como muchísima gente por lo ocurr...</td>\n",
       "      <td>tristeza</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es una mierda lo que paso pero please dejen de...</td>\n",
       "      <td>disgusto</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8402</th>\n",
       "      <td>Dembele de mierda piernas chuecas regalaste do...</td>\n",
       "      <td>ira</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8404</th>\n",
       "      <td>Dembele es un imbécil, neta es increíble lo pe...</td>\n",
       "      <td>ira</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8405</th>\n",
       "      <td>Puta q son desagradables los wnes del Barca en...</td>\n",
       "      <td>ira</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8407</th>\n",
       "      <td>Como te odio , odio tus comentarios filosófico...</td>\n",
       "      <td>ira</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8408</th>\n",
       "      <td>Miedo me da que mi país esté en manos de perso...</td>\n",
       "      <td>miedo</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7579 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text   emotion    idioma\n",
       "0     Acabo de ver la gran pérdida que estamos tenie...  tristeza  spa_Latn\n",
       "1     ¿A que vamos a reconstruir Notre Dame antes de...  tristeza  spa_Latn\n",
       "2     Desde ayer andan sufriendo por el incendio y n...       ira  spa_Latn\n",
       "3     Muy afectada como muchísima gente por lo ocurr...  tristeza  spa_Latn\n",
       "4     Es una mierda lo que paso pero please dejen de...  disgusto  spa_Latn\n",
       "...                                                 ...       ...       ...\n",
       "8402  Dembele de mierda piernas chuecas regalaste do...       ira  spa_Latn\n",
       "8404  Dembele es un imbécil, neta es increíble lo pe...       ira  spa_Latn\n",
       "8405  Puta q son desagradables los wnes del Barca en...       ira  spa_Latn\n",
       "8407  Como te odio , odio tus comentarios filosófico...       ira  spa_Latn\n",
       "8408  Miedo me da que mi país esté en manos de perso...     miedo  spa_Latn\n",
       "\n",
       "[7579 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import fasttext\n",
    "import re\n",
    "\n",
    "# Filtrar solo textos en español\n",
    "df = df[df[\"idioma\"] == \"spa_Latn\"].copy()\n",
    "\n",
    "df[[\"text\",\"emotion\", \"idioma\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "neutral     3884\n",
       "alegría     1679\n",
       "tristeza     979\n",
       "ira          797\n",
       "disgusto     153\n",
       "miedo         87\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=[\"idioma\"] )\n",
    "df['emotion'].value_counts()\n",
    "# gui = show(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar solo el último punto (si existe al final)\n",
    "df[\"text\"] = df[\"text\"].str.replace(r\"\\.$\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acabo de ver la gran pérdida que estamos tenie...</td>\n",
       "      <td>tristeza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¿A que vamos a reconstruir Notre Dame antes de...</td>\n",
       "      <td>tristeza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desde ayer andan sufriendo por el incendio y n...</td>\n",
       "      <td>ira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muy afectada como muchísima gente por lo ocurr...</td>\n",
       "      <td>tristeza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es una mierda lo que paso pero please dejen de...</td>\n",
       "      <td>disgusto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7574</th>\n",
       "      <td>Dembele de mierda piernas chuecas regalaste do...</td>\n",
       "      <td>ira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7575</th>\n",
       "      <td>Dembele es un imbécil, neta es increíble lo pe...</td>\n",
       "      <td>ira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7576</th>\n",
       "      <td>Puta q son desagradables los wnes del Barca en...</td>\n",
       "      <td>ira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7577</th>\n",
       "      <td>Como te odio , odio tus comentarios filosófico...</td>\n",
       "      <td>ira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7578</th>\n",
       "      <td>Miedo me da que mi país esté en manos de perso...</td>\n",
       "      <td>miedo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7579 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text   emotion\n",
       "0     Acabo de ver la gran pérdida que estamos tenie...  tristeza\n",
       "1     ¿A que vamos a reconstruir Notre Dame antes de...  tristeza\n",
       "2     Desde ayer andan sufriendo por el incendio y n...       ira\n",
       "3     Muy afectada como muchísima gente por lo ocurr...  tristeza\n",
       "4     Es una mierda lo que paso pero please dejen de...  disgusto\n",
       "...                                                 ...       ...\n",
       "7574  Dembele de mierda piernas chuecas regalaste do...       ira\n",
       "7575  Dembele es un imbécil, neta es increíble lo pe...       ira\n",
       "7576  Puta q son desagradables los wnes del Barca en...       ira\n",
       "7577  Como te odio , odio tus comentarios filosófico...       ira\n",
       "7578  Miedo me da que mi país esté en manos de perso...     miedo\n",
       "\n",
       "[7579 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "De50gLBNYows",
    "outputId": "193c47de-a23b-476a-f59b-b817fff2e78c"
   },
   "outputs": [],
   "source": [
    "dataToken = df.copy()\n",
    "# dataToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "id": "bv6RE8mLZKgX",
    "outputId": "927f290c-e7a7-4f1f-cce4-eb158d719f91"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3412</th>\n",
       "      <td>Buenas y tarde</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5059</th>\n",
       "      <td>Emotivo discurso en</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5776</th>\n",
       "      <td>Las Ligas ️</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>levanta su título</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5993</th>\n",
       "      <td>Mi Barcelona ganará</td>\n",
       "      <td>alegría</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6014</th>\n",
       "      <td>Medio tiempo, vs.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6253</th>\n",
       "      <td>vuelve y por</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6405</th>\n",
       "      <td>En medio de</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     text  emotion  token_count\n",
       "3412       Buenas y tarde  neutral            3\n",
       "5059  Emotivo discurso en  neutral            3\n",
       "5776          Las Ligas ️  neutral            3\n",
       "5789    levanta su título  neutral            3\n",
       "5993  Mi Barcelona ganará  alegría            3\n",
       "6014   Medio tiempo, vs.   neutral            3\n",
       "6253         vuelve y por  neutral            3\n",
       "6405          En medio de  neutral            3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Función alternativa para contar tokens utilizando split()\n",
    "def contar_tokens_simple(texto):\n",
    "    return len(texto.split())\n",
    "\n",
    "# Aplicar la función y filtrar las filas con menos de 10 tokens\n",
    "dataToken['token_count'] = dataToken['text'].apply(contar_tokens_simple)\n",
    "dataToken = dataToken[dataToken['token_count'] <= 3]\n",
    "\n",
    "# Mostrar el resultado\n",
    "dataToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "JroHmqORow3s"
   },
   "outputs": [],
   "source": [
    "# Obtener los índices de las filas donde 'token_count' es 0\n",
    "indices_a_eliminar = dataToken[dataToken['token_count'] <= 3].index\n",
    "\n",
    "# Eliminar las filas del DataFrame original (df)\n",
    "df = df.drop(index=indices_a_eliminar)\n",
    "dataToken = dataToken.drop(index=indices_a_eliminar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "gh78itlKXa6k"
   },
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "dataToken = df.copy()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "LO8o9oXfXUGN",
    "outputId": "984d5710-c71c-443c-c5bc-7ea926a2a39b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acabo de ver la gran pérdida que estamos tenie...</td>\n",
       "      <td>tristeza</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¿A que vamos a reconstruir Notre Dame antes de...</td>\n",
       "      <td>tristeza</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desde ayer andan sufriendo por el incendio y n...</td>\n",
       "      <td>ira</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muy afectada como muchísima gente por lo ocurr...</td>\n",
       "      <td>tristeza</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es una mierda lo que paso pero please dejen de...</td>\n",
       "      <td>disgusto</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7566</th>\n",
       "      <td>Dembele de mierda piernas chuecas regalaste do...</td>\n",
       "      <td>ira</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7567</th>\n",
       "      <td>Dembele es un imbécil, neta es increíble lo pe...</td>\n",
       "      <td>ira</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7568</th>\n",
       "      <td>Puta q son desagradables los wnes del Barca en...</td>\n",
       "      <td>ira</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7569</th>\n",
       "      <td>Como te odio , odio tus comentarios filosófico...</td>\n",
       "      <td>ira</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7570</th>\n",
       "      <td>Miedo me da que mi país esté en manos de perso...</td>\n",
       "      <td>miedo</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7571 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text   emotion  token_count\n",
       "0     Acabo de ver la gran pérdida que estamos tenie...  tristeza           27\n",
       "1     ¿A que vamos a reconstruir Notre Dame antes de...  tristeza           20\n",
       "2     Desde ayer andan sufriendo por el incendio y n...       ira           16\n",
       "3     Muy afectada como muchísima gente por lo ocurr...  tristeza           40\n",
       "4     Es una mierda lo que paso pero please dejen de...  disgusto           13\n",
       "...                                                 ...       ...          ...\n",
       "7566  Dembele de mierda piernas chuecas regalaste do...       ira           13\n",
       "7567  Dembele es un imbécil, neta es increíble lo pe...       ira           11\n",
       "7568  Puta q son desagradables los wnes del Barca en...       ira           13\n",
       "7569  Como te odio , odio tus comentarios filosófico...       ira           29\n",
       "7570  Miedo me da que mi país esté en manos de perso...     miedo           14\n",
       "\n",
       "[7571 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicar la función y filtrar las filas con menos de 10 tokens\n",
    "dataToken['token_count'] = dataToken['text'].apply(contar_tokens_simple)\n",
    "# dataToken = dataToken[dataToken['token_count'] <= 7]\n",
    "\n",
    "# Mostrar el resultado\n",
    "dataToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dtale.show(dataToken)\n",
    "d.open_browser() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "neutral     3877\n",
       "alegría     1678\n",
       "tristeza     979\n",
       "ira          797\n",
       "disgusto     153\n",
       "miedo         87\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acabo de ver la gran pérdida que estamos tenie...</td>\n",
       "      <td>tristeza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¿A que vamos a reconstruir Notre Dame antes de...</td>\n",
       "      <td>tristeza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desde ayer andan sufriendo por el incendio y n...</td>\n",
       "      <td>ira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muy afectada como muchísima gente por lo ocurr...</td>\n",
       "      <td>tristeza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es una mierda lo que paso pero please dejen de...</td>\n",
       "      <td>disgusto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7566</th>\n",
       "      <td>Dembele de mierda piernas chuecas regalaste do...</td>\n",
       "      <td>ira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7567</th>\n",
       "      <td>Dembele es un imbécil, neta es increíble lo pe...</td>\n",
       "      <td>ira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7568</th>\n",
       "      <td>Puta q son desagradables los wnes del Barca en...</td>\n",
       "      <td>ira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7569</th>\n",
       "      <td>Como te odio , odio tus comentarios filosófico...</td>\n",
       "      <td>ira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7570</th>\n",
       "      <td>Miedo me da que mi país esté en manos de perso...</td>\n",
       "      <td>miedo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text   emotion\n",
       "0     Acabo de ver la gran pérdida que estamos tenie...  tristeza\n",
       "1     ¿A que vamos a reconstruir Notre Dame antes de...  tristeza\n",
       "2     Desde ayer andan sufriendo por el incendio y n...       ira\n",
       "3     Muy afectada como muchísima gente por lo ocurr...  tristeza\n",
       "4     Es una mierda lo que paso pero please dejen de...  disgusto\n",
       "...                                                 ...       ...\n",
       "7566  Dembele de mierda piernas chuecas regalaste do...       ira\n",
       "7567  Dembele es un imbécil, neta es increíble lo pe...       ira\n",
       "7568  Puta q son desagradables los wnes del Barca en...       ira\n",
       "7569  Como te odio , odio tus comentarios filosófico...       ira\n",
       "7570  Miedo me da que mi país esté en manos de perso...     miedo\n",
       "\n",
       "[7571 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dtale.show(df)\n",
    "d.open_browser() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# df = pd.read_csv('../data/EMOEVENT_CLEANED_v6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar textos\n",
    "df[\"text\"] = df[\"text\"].apply(limpiar_texto)\n",
    "\n",
    "# 1. Eliminar espacio antes de coma ' ,'\n",
    "df['text'] = df['text'].str.replace(r'\\s+,', ',', regex=True)\n",
    "\n",
    "# 2. Eliminar varias comas juntas ',,,,' (todas las comas consecutivas)\n",
    "df['text'] = df['text'].str.replace(r',+', ',', regex=True)\n",
    "\n",
    "# 3. Eliminar solo el último punto al final si está solo, pero no tocar los '...'\n",
    "df['text'] = df['text'].str.replace(r'(?<!\\.\\.\\.)\\.$', '', regex=True)\n",
    "\n",
    "# 4. Eliminar el espacio antes del punto ' .'\n",
    "df['text'] = df['text'].str.replace(r'\\s+\\.', '.', regex=True)\n",
    "\n",
    "\n",
    "# 5. Eliminar el espacio antes del signo de interrogación ' ?' y el signo de exclamación ' !'\n",
    "df['text'] = df['text'].str.replace(r'\\s+\\?', '?', regex=True)\n",
    "df['text'] = df['text'].str.replace(r'\\s+\\!', '!', regex=True)\n",
    "\n",
    "# eliminar puntos finales\n",
    "df[\"text\"] = df[\"text\"].str.rstrip(\".\")\n",
    "\n",
    "# 6. Letras sueltas a eliminar, excluyendo conectores válidos como y, o, a, e\n",
    "df['text'] = df['text'].str.replace(r'\\b[b-df-hj-np-tv-z]\\b', '', regex=True)\n",
    "\n",
    "# limpiar espacios\n",
    "df['text'] = df['text'].str.replace(r'\\s+([;:!,?.])', r'\\1', regex=True)\n",
    "\n",
    "# Limpiar textos\n",
    "df[\"text\"] = df[\"text\"].apply(limpiar_texto)\n",
    "# Eliminar espacios extra al final otra vez por seguridad\n",
    "df[\"text\"] = df[\"text\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para detectar emojis en un texto\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticonos\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # símbolos y pictogramas\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transporte y mapas\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # banderas (iOS)\n",
    "    u\"\\U00002700-\\U000027BF\"  # Dingbats\n",
    "    u\"\\U0001F900-\\U0001F9FF\"  # símbolos suplementarios\n",
    "    u\"\\U00002600-\\U000026FF\"  # Miscelánea\n",
    "    \"]+\", flags=re.UNICODE)\n",
    "# Eliminar filas donde emotion es 'neutral' y el texto contiene al menos un emoji\n",
    "df = df[~((df['emotion'] == 'neutral') & (df['text'].str.contains(emoji_pattern)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/EMOEVENT_CLEANED_v10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import dtale\n",
    "# # Mostrar el DataFrame en D-Tale\n",
    "# d = dtale.show(df)\n",
    "# d.open_browser() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 23:11:50,988 - ERROR    - Exception occurred while processing request: object of type 'NoneType' has no len()\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\leo23\\OneDrive\\Documentos\\Fine_tuning_llama2\\venv\\Lib\\site-packages\\dtale\\views.py\", line 120, in _handle_exceptions\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\leo23\\OneDrive\\Documentos\\Fine_tuning_llama2\\venv\\Lib\\site-packages\\dtale\\views.py\", line 1595, in get_processes\n",
      "    [_load_process(data_id) for data_id in global_state.keys()],\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\leo23\\OneDrive\\Documentos\\Fine_tuning_llama2\\venv\\Lib\\site-packages\\dtale\\views.py\", line 1595, in <listcomp>\n",
      "    [_load_process(data_id) for data_id in global_state.keys()],\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\leo23\\OneDrive\\Documentos\\Fine_tuning_llama2\\venv\\Lib\\site-packages\\dtale\\views.py\", line 1580, in _load_process\n",
      "    rows=len(data),\n",
      "         ^^^^^^^^^\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "2025-04-29 23:11:55,553 - INFO     - Executing shutdown...\n",
      "2025-04-29 23:11:55,553 - INFO     - Not running with the Werkzeug Server, exiting by searching gc for BaseWSGIServer\n",
      "2025-04-29 23:11:55,641 - ERROR    - weakly-referenced object no longer exists\n",
      "2025-04-29 23:11:55,643 - ERROR    - weakly-referenced object no longer exists\n",
      "C:\\Users\\leo23\\OneDrive\\Documentos\\Fine_tuning_llama2\\venv\\Lib\\site-packages\\dtale\\app.py:445: FutureWarning:\n",
      "\n",
      "`torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "\n",
      "2025-04-29 23:11:55,673 - ERROR    - weakly-referenced object no longer exists\n",
      "2025-04-29 23:11:55,674 - ERROR    - weakly-referenced object no longer exists\n"
     ]
    }
   ],
   "source": [
    "# # --------------------------------------------------------\n",
    "# # 2. Cargar modelo y tokenizador\n",
    "# # --------------------------------------------------------\n",
    "# from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# model_name = \"mrm8488/bert-spanish-cased-finetuned-ner\"  #\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForTokenClassification.from_pretrained(model_name).to(\"cuda\" or \"cpu\")\n",
    "\n",
    "# # --------------------------------------------------------\n",
    "# # 3. Función optimizada para detección de errores (batch)\n",
    "# # --------------------------------------------------------\n",
    "# def detectar_errores_lote(textos, batch_size=16):\n",
    "#     errores_totales = []\n",
    "    \n",
    "#     # Procesar en lotes para mayor eficiencia\n",
    "#     for i in tqdm(range(0, len(textos), batch_size), desc=\"Procesando textos\"):\n",
    "#         batch = textos[i:i+batch_size]\n",
    "        \n",
    "#         # Tokenizar y enviar a GPU\n",
    "#         inputs = tokenizer(\n",
    "#             batch,\n",
    "#             padding=True,\n",
    "#             truncation=True,\n",
    "#             return_tensors=\"pt\"\n",
    "#         ).to(device)\n",
    "        \n",
    "#         # Inferencia\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(**inputs)\n",
    "        \n",
    "#         # Decodificar resultados\n",
    "#         predictions = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "        \n",
    "#         # Procesar cada texto del lote\n",
    "#         for j in range(len(batch)):\n",
    "#             tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][j])\n",
    "#             errores = [\n",
    "#                 token.replace(\"##\", \"\") \n",
    "#                 for token, pred in zip(tokens, predictions[j]) \n",
    "#                 if token not in [\"[CLS]\", \"[SEP]\"] and pred == 1\n",
    "#             ]\n",
    "#             errores_totales.append(errores)\n",
    "    \n",
    "#     return errores_totales\n",
    "\n",
    "# # --------------------------------------------------------\n",
    "# # 4. Aplicar al DataFrame\n",
    "# # --------------------------------------------------------\n",
    "# # Convertir la columna 'text' a lista\n",
    "# textos = df[\"text\"].tolist()\n",
    "\n",
    "# # Procesar en lotes usando GPU\n",
    "# df[\"errores_bert\"] = detectar_errores_lote(textos, batch_size=16)\n",
    "\n",
    "# # Mostrar resultados\n",
    "# print(df[[\"text\", \"errores_bert\"]].head())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
