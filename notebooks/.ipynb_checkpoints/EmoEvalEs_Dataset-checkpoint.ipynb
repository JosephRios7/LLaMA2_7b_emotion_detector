{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XSFYNYnEWD3y",
    "outputId": "b6673c80-78a0-49b5-c65a-548212af7dab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8409 entries, 0 to 8408\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         8409 non-null   int64 \n",
      " 1   tweet      8409 non-null   object\n",
      " 2   emotion    8409 non-null   object\n",
      " 3   offensive  8409 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 262.9+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv('../data/emoevent_es.csv', sep='\\t')\n",
    "\n",
    "df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dtale\n",
    "\n",
    "# Mostrar el DataFrame en D-Tale\n",
    "# d = dtale.show(df)\n",
    "# d.open_browser() \n",
    "# d._main_url\n",
    "# dtale.utils.get_open_dtales() \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "22jmr_M5W-n4"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"id\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "1LVTtvGDrqpV",
    "outputId": "ce166545-09f1-47cf-a2b4-73860bb2b59e"
   },
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Gm2unaVFoxaP"
   },
   "outputs": [],
   "source": [
    "# Contar las emociones ofensivas\n",
    "offensive_emotion_counts = df[df['offensive'] == 1]['emotion'].value_counts()\n",
    "\n",
    "# Convertir a DataFrame para visualizaci√≥n\n",
    "offensive_emotion_counts_df = offensive_emotion_counts.reset_index()\n",
    "offensive_emotion_counts_df.columns = ['emotion', 'offensive_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "others      4127\n",
       "joy         1815\n",
       "sadness     1009\n",
       "anger        857\n",
       "surprise     344\n",
       "disgust      161\n",
       "fear          96\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "-oPuyJMWrkK0",
    "outputId": "67bfeeb4-e937-45b2-a72b-8b26399745c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>offensive_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>others</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>joy</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surprise</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sadness</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fear</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    emotion  offensive_count\n",
       "0     anger              378\n",
       "1    others              111\n",
       "2   disgust               94\n",
       "3       joy               72\n",
       "4  surprise               37\n",
       "5   sadness               10\n",
       "6      fear                4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offensive_emotion_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Gc9A7adnXb5f"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"offensive\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TJhpNVTaXIR6"
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'tweet': 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "xut8mgsfXpyh",
    "outputId": "f07d30da-5309-4d09-a0ba-bd5add6e46fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, emotion]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filas_repetidas = df[df.duplicated()]\n",
    "filas_repetidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q2t3lQlUXxUE",
    "outputId": "cba267d5-69c6-4f02-8cd4-622954e1d4c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "others      4127\n",
      "joy         1815\n",
      "sadness     1009\n",
      "anger        857\n",
      "surprise     344\n",
      "disgust      161\n",
      "fear          96\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "emotion_distribution = df['emotion'].value_counts()\n",
    "\n",
    "# Mostrar la distribuci√≥n\n",
    "print(emotion_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "others     4127\n",
      "joy        1815\n",
      "sadness    1009\n",
      "anger       857\n",
      "disgust     161\n",
      "fear         96\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Eliminar las filas donde emotion sea 'surprise'\n",
    "df = df[df[\"emotion\"] != \"surprise\"].copy()\n",
    "\n",
    "# Verificamos que ya no est√© 'surprise' en la distribuci√≥n\n",
    "print(df[\"emotion\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "HdVnZZ7oX37e",
    "outputId": "4a3654d2-230d-4c2d-e86a-bd1851d2bbd7"
   },
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "EjqC0Ay-Zcmo"
   },
   "outputs": [],
   "source": [
    "# Mapeo de etiquetas de ingl√©s a espa√±ol\n",
    "emotion_mapping = {\n",
    "    'others': 'neutral',#segun indica la p√°gina oficial https://competitions.codalab.org/competitions/28682\n",
    "    'anger': 'ira',\n",
    "    'disgust': 'disgusto',\n",
    "    'sadness': 'tristeza',\n",
    "    'joy': 'alegr√≠a',\n",
    "    'fear': 'miedo',\n",
    "    # 'surprise': 'sorpresa'\n",
    "}\n",
    "\n",
    "df['emotion'] = df['emotion'].map(emotion_mapping) # columna 'emotion' con valores en espa√±ol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WIISuq-ZZnxK",
    "outputId": "097bbd6c-5c6e-4f4e-ba6a-a4e2437613eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "neutral     4127\n",
      "alegr√≠a     1815\n",
      "tristeza    1009\n",
      "ira          857\n",
      "disgusto     161\n",
      "miedo         96\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['emotion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "neutral     4127\n",
      "alegr√≠a     1815\n",
      "tristeza    1009\n",
      "ira          857\n",
      "disgusto     161\n",
      "miedo         96\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['emotion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "2fIYEhjEaD5y",
    "outputId": "8d04aec6-bd5e-46f1-f62b-cfe75e95e693"
   },
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_before</th>\n",
       "      <th>word_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acabo de ver la gran p√©rdida que estamos tenie...</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USER ¬øA que vamos a reconstruir Notre Dame ant...</td>\n",
       "      <td>None</td>\n",
       "      <td>URL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desde ayer andan sufriendo por el incendio de ...</td>\n",
       "      <td>de</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muy afectada -como much√≠sima gente- por lo ocu...</td>\n",
       "      <td>a</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es una mierda lo que paso en HASHTAG pero plea...</td>\n",
       "      <td>en</td>\n",
       "      <td>pero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8404</th>\n",
       "      <td>Dembele es un imb√©cil, neta es incre√≠ble lo pe...</td>\n",
       "      <td>None</td>\n",
       "      <td>HASHTAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8405</th>\n",
       "      <td>HASHTAG Puta q son desagradables los wnes del ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Puta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8406</th>\n",
       "      <td>Puta que me cae mal Su√°rez ctm HASHTAG</td>\n",
       "      <td>ctm</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8407</th>\n",
       "      <td>Como te odio USER, odio tus comentarios filos√≥...</td>\n",
       "      <td>None</td>\n",
       "      <td>HASHTAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8408</th>\n",
       "      <td>Miedo me da que mi pa√≠s est√© en manos de perso...</td>\n",
       "      <td>None</td>\n",
       "      <td>HASHTAG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8043 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text word_before word_after\n",
       "0     Acabo de ver la gran p√©rdida que estamos tenie...          en       None\n",
       "1     USER ¬øA que vamos a reconstruir Notre Dame ant...        None        URL\n",
       "2     Desde ayer andan sufriendo por el incendio de ...          de          y\n",
       "3     Muy afectada -como much√≠sima gente- por lo ocu...           a       None\n",
       "4     Es una mierda lo que paso en HASHTAG pero plea...          en       pero\n",
       "...                                                 ...         ...        ...\n",
       "8404  Dembele es un imb√©cil, neta es incre√≠ble lo pe...        None    HASHTAG\n",
       "8405  HASHTAG Puta q son desagradables los wnes del ...        None       Puta\n",
       "8406             Puta que me cae mal Su√°rez ctm HASHTAG         ctm       None\n",
       "8407  Como te odio USER, odio tus comentarios filos√≥...        None    HASHTAG\n",
       "8408  Miedo me da que mi pa√≠s est√© en manos de perso...        None    HASHTAG\n",
       "\n",
       "[8043 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def get_words_around_hashtag(text):\n",
    "    # Patr√≥n para encontrar palabra antes y despu√©s de HASHTAG\n",
    "    match = re.search(r'(\\w+)?\\s*HASHTAG\\s*(\\w+)?', text)\n",
    "    if match:\n",
    "        return match.group(1), match.group(2)\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Aplicamos la funci√≥n a cada tweet\n",
    "df[['word_before', 'word_after']] = df['text'].apply(lambda x: pd.Series(get_words_around_hashtag(str(x))))\n",
    "# Filtrar los que tienen HASHTAG\n",
    "df_hashtag = df[df['text'].str.contains(\"HASHTAG\", na=False)]\n",
    "\n",
    "# Mostrar los resultados\n",
    "df_hashtag[['text', 'word_before', 'word_after']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar y filtrar palabras antes de HASHTAG con frecuencia > 1\n",
    "before_common = df['word_before'].value_counts()\n",
    "before_common = before_common[before_common > 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_after\n",
      "HASHTAG       2291\n",
      "URL            561\n",
      "y              223\n",
      "en             120\n",
      "es             117\n",
      "              ... \n",
      "qu√©              3\n",
      "cada             3\n",
      "eres             3\n",
      "creo             3\n",
      "celebramos       3\n",
      "Name: count, Length: 121, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contar y filtrar palabras despu√©s de HASHTAG con frecuencia > 1\n",
    "after_common = df['word_after'].value_counts()\n",
    "after_common = after_common[after_common > 2]\n",
    "print(after_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a DataFrame si quieres trabajar con ellas\n",
    "before_df = before_common.reset_index()\n",
    "before_df.columns = ['word_before', 'frequency']\n",
    "\n",
    "after_df = after_common.reset_index()\n",
    "after_df.columns = ['word_after', 'frequency']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "orzkd0rPaAiw"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    tweet = re.sub(r'  ', ' ', tweet)\n",
    "    tweet = re.sub(r'@USER', ' ', tweet)\n",
    "    tweet = re.sub(r'USER', ' ', tweet)\n",
    "    tweet = re.sub(r'DE HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r'En HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r'El HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r'La HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' del HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' de HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' por HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' en HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' el HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' las HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' a los HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' los HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' al HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' la HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' la HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' ni HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' e HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' a HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' o HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' es HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' con HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' como HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' para HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' y HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' Este HASHTAG,', ' ', tweet)\n",
    "    tweet = re.sub(r'HASHTAG', ' ', tweet)\n",
    "    tweet = re.sub(r' y URL', ' ', tweet)\n",
    "    tweet = re.sub(r'URL', ' ', tweet)\n",
    "    tweet = re.sub(r'l@s', 'los', tweet)\n",
    "    tweet = re.sub(r'L@s', 'los', tweet)\n",
    "    tweet = re.sub(r'tod@s', 'todos', tweet)\n",
    "    tweet = re.sub(r'Tod@s', 'todos', tweet)\n",
    "    tweet = re.sub(r'est@s', 'estos', tweet)\n",
    "    tweet = re.sub(r'alumn@s', 'alumnos', tweet)\n",
    "    tweet = re.sub(r'hij@s', 'hijos', tweet)\n",
    "    tweet = re.sub(r'ni√±@s', 'ni√±os', tweet)\n",
    "    tweet = re.sub(r'nosotr@s', 'nosotros', tweet)\n",
    "    tweet = re.sub(r'compa√±er@s', 'compa√±eros', tweet)\n",
    "    tweet = re.sub(r'cat√≥lic@s', 'cat√≥licos', tweet)\n",
    "    tweet = re.sub(r'http\\S+|www.\\S+', ' ', tweet)  # eliminar urls\n",
    "    # tweet = re.sub(r'[^a-zA-Z√±√ë√°√©√≠√≥√∫√Å√â√ç√ì√ö\\s]', '', tweet)  # eliminar s√≠mbolos\n",
    "    # tweet = tweet.lower()\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet).strip()  # eliminar espacios extras\n",
    "    return tweet\n",
    "\n",
    "df['text'] = df['text'].apply(clean_tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Unir todos los textos en uno solo\n",
    "all_text = ' '.join(df['text'].astype(str))\n",
    "\n",
    "# Contar cada caracter\n",
    "char_counts = Counter(all_text)\n",
    "\n",
    "# Mostrar los caracteres y sus conteos ordenados por frecuencia\n",
    "# for char, count in char_counts.most_common():\n",
    "#     print(f\"'{char}': {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Paso 1: eliminar texto entre corchetes\n",
    "df['text'] = df['text'].astype(str).str.replace(r'\\[.*?\\]', '', regex=True)\n",
    "\n",
    "# Paso 2: listar palabras que contienen @\n",
    "palabras_con_arroba = df['text'].str.findall(r'\\S*@\\S+')\n",
    "\n",
    "# Paso 3: eliminar palabras que contienen @\n",
    "df['text'] = df['text'].str.replace(r'\\S*@\\S+', '', regex=True)\n",
    "\n",
    "# Paso 4: corregir acentos mal escritos\n",
    "df['text'] = (\n",
    "    df['text']\n",
    "    .str.replace('√†', '√°')\n",
    "    .str.replace('√®', '√©')\n",
    "    .str.replace('√¨', '√≠')\n",
    "    .str.replace('√≤', '√≥')\n",
    "    .str.replace('√π', '√∫')\n",
    "    .str.replace('√Ä', '√Å')\n",
    "    .str.replace('√à', '√â')\n",
    "    .str.replace('√å', '√ç')\n",
    "    .str.replace('√í', '√ì')\n",
    "    .str.replace('√ô', '√ö')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dtale\n",
    "\n",
    "# Mostrar el DataFrame en D-Tale\n",
    "d = dtale.show(palabras_con_arroba)\n",
    "d.open_browser() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' ': 156960\n",
      "'e': 83905\n",
      "'a': 75521\n",
      "'o': 59076\n",
      "'s': 47587\n",
      "'n': 43077\n",
      "'r': 40986\n",
      "'i': 36949\n",
      "'l': 35572\n",
      "'d': 30443\n",
      "'t': 27693\n",
      "'u': 26774\n",
      "'c': 23061\n",
      "'m': 18537\n",
      "'p': 15787\n",
      "'.': 10136\n",
      "'b': 7488\n",
      "'g': 7339\n",
      "'q': 7269\n",
      "'v': 7079\n",
      "'h': 6715\n",
      "'y': 6680\n",
      "',': 5574\n",
      "'f': 4159\n",
      "'E': 4112\n",
      "'√≠': 3509\n",
      "'√°': 3285\n",
      "'√≥': 3168\n",
      "'A': 3045\n",
      "'j': 2922\n",
      "'L': 2596\n",
      "'!': 2462\n",
      "'z': 2461\n",
      "'S': 2286\n",
      "'C': 2070\n",
      "'M': 2041\n",
      "'N': 1987\n",
      "'O': 1957\n",
      "'√©': 1935\n",
      "'P': 1817\n",
      "'D': 1588\n",
      "'√±': 1539\n",
      "'T': 1351\n",
      "'R': 1314\n",
      "'I': 1198\n",
      "'?': 1046\n",
      "'U': 1009\n",
      "'V': 916\n",
      "'H': 848\n",
      "'B': 819\n",
      "'x': 772\n",
      "'Q': 768\n",
      "'√∫': 735\n",
      "'G': 735\n",
      "'F': 662\n",
      "'Y': 641\n",
      "'¬°': 532\n",
      "'¬ø': 507\n",
      "'Ô∏è': 499\n",
      "'J': 403\n",
      "'k': 168\n",
      "'‚ù§': 152\n",
      "'üòÇ': 132\n",
      "'w': 104\n",
      "'√ß': 96\n",
      "'üò≠': 90\n",
      "';': 89\n",
      "'X': 87\n",
      "'Z': 86\n",
      "'üò¢': 76\n",
      "'üòç': 75\n",
      "'√â': 74\n",
      "'√ì': 73\n",
      "'üôè': 68\n",
      "'√ç': 68\n",
      "'üí™': 65\n",
      "'ü§î': 63\n",
      "'üò±': 59\n",
      "'√ë': 57\n",
      "'√Å': 53\n",
      "'√º': 52\n",
      "'K': 45\n",
      "'W': 40\n",
      "'üòî': 37\n",
      "'üòâ': 31\n",
      "'üòú': 29\n",
      "'üòé': 26\n",
      "'üòä': 25\n",
      "'√ö': 20\n",
      "'ü§©': 17\n",
      "'üò•': 14\n",
      "'ü§ó': 14\n",
      "'üòì': 11\n",
      "'üòò': 11\n",
      "'üòÖ': 11\n",
      "'ü•∞': 10\n",
      "'üò∞': 9\n",
      "'√á': 9\n",
      "'üôà': 8\n",
      "'üòñ': 8\n",
      "'ü•∫': 7\n",
      "'üò®': 6\n",
      "'üò°': 5\n",
      "'ü§¨': 5\n",
      "'üò©': 5\n",
      "'üôä': 4\n",
      "'üôÇ': 3\n",
      "'üôÄ': 2\n",
      "'üò§': 2\n",
      "'üôâ': 2\n",
      "'√ú': 2\n",
      "'üòø': 1\n",
      "'üôÉ': 1\n",
      "'üòá': 1\n"
     ]
    }
   ],
   "source": [
    "# def limpiar_texto(texto):\n",
    "#     # Elimina todo lo que no est√© en el conjunto permitido\n",
    "#     return ''.join(re.findall(caracteres_permitidos, texto))\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    # Reemplaza caracteres no permitidos por espacio\n",
    "    return ''.join(c if re.match(caracteres_permitidos, c) else ' ' for c in texto)\n",
    "\n",
    "# Letras latinas con tildes y √±\n",
    "letras = 'a-zA-Z√°√©√≠√≥√∫√Å√â√ç√ì√ö√±√ë√º√ú√ß√á'\n",
    "\n",
    "# D√≠gitos\n",
    "digitos = '0-9'\n",
    "\n",
    "# Signos de puntuaci√≥n b√°sicos\n",
    "# puntuacion = r\"\\.\\,\\!\\¬°\\?\\¬ø\\:;\\\"\\'\\-\\(\\)\"\n",
    "puntuacion = r'\\.\\,\\!\\¬°\\?\\¬ø\\;'\n",
    "\n",
    "# Emojis de emociones: puedes ampliarlos si usas m√°s\n",
    "emojis = '‚ù§Ô∏èüòÇüò≠üò±üò¢üòçüòîü§îüôèüí™üòúüòéüòäüò°ü§¨ü§óü§©üòÖüòâüòòü•∞üòáüôÇüôÉü•∫üòñüò§üò®üò©üò∞üòìüò•üòøüòæüòºüôÄüôàüôâüôä'\n",
    "\n",
    "# Todos juntos\n",
    "caracteres_permitidos = f\"[{letras}{puntuacion}{emojis} ]\" #{digitos}\n",
    "\n",
    "df['text_limpio'] = df['text'].astype(str).apply(limpiar_texto)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "contador = Counter(''.join(df['text_limpio']))\n",
    "for char, count in contador.most_common():\n",
    "    print(f\"'{char}': {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gui3 = show(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text_limpio']\n",
    "df = df.drop(columns=[\"word_before\", \"word_after\", \"text_limpio\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Funci√≥n para limpiar texto\n",
    "def limpiar_texto(texto):\n",
    "    texto = str(texto)  # Por si hay NaNs u objetos raros\n",
    "    texto = texto.strip()  # Eliminar espacios al principio y al final\n",
    "    texto = re.sub(r'\\s+', ' ', texto)  # Reemplaza m√∫ltiples espacios por uno\n",
    "    return texto\n",
    "\n",
    "# Limpiar textos\n",
    "df[\"text\"] = df[\"text\"].apply(limpiar_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar puntos y comas al inicio del texto\n",
    "df['text'] = df['text'].str.replace(r'^[.,]+', '', regex=True).str.lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fasttext-wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc9cbe3d3fa4bbf845f5d925b2a224a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Detectando idiomas (sensitivo):   0%|          | 0/8065 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuci√≥n de idiomas detectados:\n",
      "idioma\n",
      "spa_Latn          7579\n",
      "low_confidence     330\n",
      "yue_Hant            74\n",
      "kor_Hang            35\n",
      "glg_Latn             9\n",
      "ast_Latn             8\n",
      "por_Latn             8\n",
      "ita_Latn             4\n",
      "cat_Latn             4\n",
      "epo_Latn             3\n",
      "fra_Latn             2\n",
      "lmo_Latn             1\n",
      "hun_Latn             1\n",
      "deu_Latn             1\n",
      "tsn_Latn             1\n",
      "gaz_Latn             1\n",
      "ces_Latn             1\n",
      "vec_Latn             1\n",
      "pap_Latn             1\n",
      "oci_Latn             1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>idioma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acabo de ver la gran p√©rdida que estamos tenie...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¬øA que vamos a reconstruir Notre Dame antes de...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desde ayer andan sufriendo por el incendio y n...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muy afectada como much√≠sima gente por lo ocurr...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es una mierda lo que paso pero please dejen de...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    idioma\n",
       "0  Acabo de ver la gran p√©rdida que estamos tenie...  spa_Latn\n",
       "1  ¬øA que vamos a reconstruir Notre Dame antes de...  spa_Latn\n",
       "2  Desde ayer andan sufriendo por el incendio y n...  spa_Latn\n",
       "3  Muy afectada como much√≠sima gente por lo ocurr...  spa_Latn\n",
       "4  Es una mierda lo que paso pero please dejen de...  spa_Latn"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "\n",
    "# Cargar modelo fastText entrenado para identificaci√≥n de idiomas\n",
    "model_path = r\"C:\\Users\\leo23\\OneDrive\\Documentos\\Fine_tuning_llama2\\models\\fasttext\\models--facebook--fasttext-language-identification\\snapshots\\3af127d4124fc58b75666f3594bb5143b9757e78\\model.bin\"\n",
    "language_detector = fasttext.load_model(model_path)\n",
    "\n",
    "# Funci√≥n mejorada para preprocesar y detectar idioma\n",
    "def detect_language(text: str, threshold: float = 0.75) -> str:\n",
    "    try:\n",
    "        if pd.isna(text) or len(text.strip()) < 3:\n",
    "            return \"unknown\"\n",
    "        \n",
    "        # Limpieza del texto\n",
    "        clean_text = re.sub(r'[^\\w\\s]', '', text).strip().replace(\"\\n\", \" \")\n",
    "        \n",
    "        # Obtener las 3 predicciones m√°s probables\n",
    "        labels, probabilities = language_detector.predict(clean_text, k=3)\n",
    "        \n",
    "        if probabilities[0] < threshold:\n",
    "            return \"low_confidence\"\n",
    "        \n",
    "        return labels[0].split(\"__\")[-1]\n",
    "    except Exception as e:\n",
    "        return \"error\"\n",
    "\n",
    "# Aplicar detecci√≥n con progreso\n",
    "tqdm.pandas(desc=\"Detectando idiomas (sensitivo)\")\n",
    "df[\"idioma\"] = df[\"text\"].progress_apply(detect_language)\n",
    "\n",
    "# Guardar resultados\n",
    "df.to_csv(\"../data/Emoevent_dataset_con_idioma.csv\", index=False)\n",
    "\n",
    "# Mostrar ejemplo\n",
    "print(\"Distribuci√≥n de idiomas detectados:\")\n",
    "print(df[\"idioma\"].value_counts())\n",
    "\n",
    "df[[\"text\", \"idioma\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fasttext\n",
    "# from huggingface_hub import hf_hub_download\n",
    "# import fasttext\n",
    "# import pandas as pd\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# # Ruta al modelo (usa la ruta completa de tu sistema)\n",
    "# model_path = r\"C:\\Users\\leo23\\OneDrive\\Documentos\\Fine_tuning_llama2\\models\\fasttext\\models--facebook--fasttext-language-identification\\snapshots\\3af127d4124fc58b75666f3594bb5143b9757e78\\model.bin\"\n",
    "\n",
    "# # Cargar el modelo\n",
    "# language_detector = fasttext.load_model(model_path)\n",
    "\n",
    "# # 2. Funci√≥n para detectar idioma con manejo de errores\n",
    "# def detect_language(text: str) -> str:\n",
    "#     try:\n",
    "#         if pd.isna(text) or len(text.strip()) < 3:  # Manejar textos vac√≠os/cortos\n",
    "#             return \"unknown\"\n",
    "#         predictions = language_detector.predict(text.replace(\"\\n\", \" \"), k=1)\n",
    "#         return predictions[0][0].split(\"__\")[-1]\n",
    "#     except:\n",
    "#         return \"error\"\n",
    "\n",
    "# # 3. Aplicar detecci√≥n a todo el DataFrame con barra de progreso\n",
    "# tqdm.pandas(desc=\"Detectando idiomas\")\n",
    "# df[\"idioma\"] = df[\"text\"].progress_apply(detect_language)\n",
    "\n",
    "# # 4. Analizar resultados\n",
    "# print(\"Conteo de idiomas identificados:\")\n",
    "# df[\"idioma\"].value_counts()\n",
    "\n",
    "# # Guarda el resultado en un nuevo archivo CSV\n",
    "# df.to_csv(\"../data/Emoevent_dataset_con_idioma.csv\", index=False)\n",
    "\n",
    "# # Muestra los primeros ejemplos para verificar\n",
    "# df[[\"text\", \"idioma\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de idiomas identificados:\n",
      "idioma\n",
      "spa_Latn          7579\n",
      "low_confidence     330\n",
      "yue_Hant            74\n",
      "kor_Hang            35\n",
      "glg_Latn             9\n",
      "ast_Latn             8\n",
      "por_Latn             8\n",
      "ita_Latn             4\n",
      "cat_Latn             4\n",
      "epo_Latn             3\n",
      "fra_Latn             2\n",
      "lmo_Latn             1\n",
      "hun_Latn             1\n",
      "deu_Latn             1\n",
      "tsn_Latn             1\n",
      "gaz_Latn             1\n",
      "ces_Latn             1\n",
      "vec_Latn             1\n",
      "pap_Latn             1\n",
      "oci_Latn             1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>idioma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acabo de ver la gran p√©rdida que estamos tenie...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¬øA que vamos a reconstruir Notre Dame antes de...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desde ayer andan sufriendo por el incendio y n...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muy afectada como much√≠sima gente por lo ocurr...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es una mierda lo que paso pero please dejen de...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8404</th>\n",
       "      <td>Dembele es un imb√©cil, neta es incre√≠ble lo pe...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8405</th>\n",
       "      <td>Puta q son desagradables los wnes del Barca en...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8406</th>\n",
       "      <td>Puta que me cae mal Su√°rez ctm</td>\n",
       "      <td>low_confidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8407</th>\n",
       "      <td>Como te odio , odio tus comentarios filos√≥fico...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8408</th>\n",
       "      <td>Miedo me da que mi pa√≠s est√© en manos de perso...</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8065 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text          idioma\n",
       "0     Acabo de ver la gran p√©rdida que estamos tenie...        spa_Latn\n",
       "1     ¬øA que vamos a reconstruir Notre Dame antes de...        spa_Latn\n",
       "2     Desde ayer andan sufriendo por el incendio y n...        spa_Latn\n",
       "3     Muy afectada como much√≠sima gente por lo ocurr...        spa_Latn\n",
       "4     Es una mierda lo que paso pero please dejen de...        spa_Latn\n",
       "...                                                 ...             ...\n",
       "8404  Dembele es un imb√©cil, neta es incre√≠ble lo pe...        spa_Latn\n",
       "8405  Puta q son desagradables los wnes del Barca en...        spa_Latn\n",
       "8406                     Puta que me cae mal Su√°rez ctm  low_confidence\n",
       "8407  Como te odio , odio tus comentarios filos√≥fico...        spa_Latn\n",
       "8408  Miedo me da que mi pa√≠s est√© en manos de perso...        spa_Latn\n",
       "\n",
       "[8065 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Contar la cantidad de ocurrencias por cada idioma\n",
    "conteo_idiomas = df[\"idioma\"].value_counts()\n",
    "print(\"Conteo de idiomas identificados:\")\n",
    "print(conteo_idiomas)\n",
    "\n",
    "# Muestra los primeros registros del dataset con la columna \"idioma\"\n",
    "display(df[[\"text\", \"idioma\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>idioma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acabo de ver la gran p√©rdida que estamos tenie...</td>\n",
       "      <td>tristeza</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¬øA que vamos a reconstruir Notre Dame antes de...</td>\n",
       "      <td>tristeza</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desde ayer andan sufriendo por el incendio y n...</td>\n",
       "      <td>ira</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muy afectada como much√≠sima gente por lo ocurr...</td>\n",
       "      <td>tristeza</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es una mierda lo que paso pero please dejen de...</td>\n",
       "      <td>disgusto</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8402</th>\n",
       "      <td>Dembele de mierda piernas chuecas regalaste do...</td>\n",
       "      <td>ira</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8404</th>\n",
       "      <td>Dembele es un imb√©cil, neta es incre√≠ble lo pe...</td>\n",
       "      <td>ira</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8405</th>\n",
       "      <td>Puta q son desagradables los wnes del Barca en...</td>\n",
       "      <td>ira</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8407</th>\n",
       "      <td>Como te odio , odio tus comentarios filos√≥fico...</td>\n",
       "      <td>ira</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8408</th>\n",
       "      <td>Miedo me da que mi pa√≠s est√© en manos de perso...</td>\n",
       "      <td>miedo</td>\n",
       "      <td>spa_Latn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7579 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text   emotion    idioma\n",
       "0     Acabo de ver la gran p√©rdida que estamos tenie...  tristeza  spa_Latn\n",
       "1     ¬øA que vamos a reconstruir Notre Dame antes de...  tristeza  spa_Latn\n",
       "2     Desde ayer andan sufriendo por el incendio y n...       ira  spa_Latn\n",
       "3     Muy afectada como much√≠sima gente por lo ocurr...  tristeza  spa_Latn\n",
       "4     Es una mierda lo que paso pero please dejen de...  disgusto  spa_Latn\n",
       "...                                                 ...       ...       ...\n",
       "8402  Dembele de mierda piernas chuecas regalaste do...       ira  spa_Latn\n",
       "8404  Dembele es un imb√©cil, neta es incre√≠ble lo pe...       ira  spa_Latn\n",
       "8405  Puta q son desagradables los wnes del Barca en...       ira  spa_Latn\n",
       "8407  Como te odio , odio tus comentarios filos√≥fico...       ira  spa_Latn\n",
       "8408  Miedo me da que mi pa√≠s est√© en manos de perso...     miedo  spa_Latn\n",
       "\n",
       "[7579 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import fasttext\n",
    "import re\n",
    "\n",
    "# Filtrar solo textos en espa√±ol\n",
    "df = df[df[\"idioma\"] == \"spa_Latn\"].copy()\n",
    "\n",
    "df[[\"text\",\"emotion\", \"idioma\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "neutral     3884\n",
       "alegr√≠a     1679\n",
       "tristeza     979\n",
       "ira          797\n",
       "disgusto     153\n",
       "miedo         87\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=[\"idioma\"] )\n",
    "df['emotion'].value_counts()\n",
    "# gui = show(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar solo el √∫ltimo punto (si existe al final)\n",
    "df[\"text\"] = df[\"text\"].str.replace(r\"\\.$\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acabo de ver la gran p√©rdida que estamos tenie...</td>\n",
       "      <td>tristeza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¬øA que vamos a reconstruir Notre Dame antes de...</td>\n",
       "      <td>tristeza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desde ayer andan sufriendo por el incendio y n...</td>\n",
       "      <td>ira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muy afectada como much√≠sima gente por lo ocurr...</td>\n",
       "      <td>tristeza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es una mierda lo que paso pero please dejen de...</td>\n",
       "      <td>disgusto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7574</th>\n",
       "      <td>Dembele de mierda piernas chuecas regalaste do...</td>\n",
       "      <td>ira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7575</th>\n",
       "      <td>Dembele es un imb√©cil, neta es incre√≠ble lo pe...</td>\n",
       "      <td>ira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7576</th>\n",
       "      <td>Puta q son desagradables los wnes del Barca en...</td>\n",
       "      <td>ira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7577</th>\n",
       "      <td>Como te odio , odio tus comentarios filos√≥fico...</td>\n",
       "      <td>ira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7578</th>\n",
       "      <td>Miedo me da que mi pa√≠s est√© en manos de perso...</td>\n",
       "      <td>miedo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7579 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text   emotion\n",
       "0     Acabo de ver la gran p√©rdida que estamos tenie...  tristeza\n",
       "1     ¬øA que vamos a reconstruir Notre Dame antes de...  tristeza\n",
       "2     Desde ayer andan sufriendo por el incendio y n...       ira\n",
       "3     Muy afectada como much√≠sima gente por lo ocurr...  tristeza\n",
       "4     Es una mierda lo que paso pero please dejen de...  disgusto\n",
       "...                                                 ...       ...\n",
       "7574  Dembele de mierda piernas chuecas regalaste do...       ira\n",
       "7575  Dembele es un imb√©cil, neta es incre√≠ble lo pe...       ira\n",
       "7576  Puta q son desagradables los wnes del Barca en...       ira\n",
       "7577  Como te odio , odio tus comentarios filos√≥fico...       ira\n",
       "7578  Miedo me da que mi pa√≠s est√© en manos de perso...     miedo\n",
       "\n",
       "[7579 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "De50gLBNYows",
    "outputId": "193c47de-a23b-476a-f59b-b817fff2e78c"
   },
   "outputs": [],
   "source": [
    "dataToken = df.copy()\n",
    "# dataToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "id": "bv6RE8mLZKgX",
    "outputId": "927f290c-e7a7-4f1f-cce4-eb158d719f91"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3412</th>\n",
       "      <td>Buenas y tarde</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5059</th>\n",
       "      <td>Emotivo discurso en</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5776</th>\n",
       "      <td>Las Ligas Ô∏è</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>levanta su t√≠tulo</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5993</th>\n",
       "      <td>Mi Barcelona ganar√°</td>\n",
       "      <td>alegr√≠a</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6014</th>\n",
       "      <td>Medio tiempo, vs.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6253</th>\n",
       "      <td>vuelve y por</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6405</th>\n",
       "      <td>En medio de</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     text  emotion  token_count\n",
       "3412       Buenas y tarde  neutral            3\n",
       "5059  Emotivo discurso en  neutral            3\n",
       "5776          Las Ligas Ô∏è  neutral            3\n",
       "5789    levanta su t√≠tulo  neutral            3\n",
       "5993  Mi Barcelona ganar√°  alegr√≠a            3\n",
       "6014   Medio tiempo, vs.   neutral            3\n",
       "6253         vuelve y por  neutral            3\n",
       "6405          En medio de  neutral            3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Funci√≥n alternativa para contar tokens utilizando split()\n",
    "def contar_tokens_simple(texto):\n",
    "    return len(texto.split())\n",
    "\n",
    "# Aplicar la funci√≥n y filtrar las filas con menos de 10 tokens\n",
    "dataToken['token_count'] = dataToken['text'].apply(contar_tokens_simple)\n",
    "dataToken = dataToken[dataToken['token_count'] <= 3]\n",
    "\n",
    "# Mostrar el resultado\n",
    "dataToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "JroHmqORow3s"
   },
   "outputs": [],
   "source": [
    "# Obtener los √≠ndices de las filas donde 'token_count' es 0\n",
    "indices_a_eliminar = dataToken[dataToken['token_count'] <= 3].index\n",
    "\n",
    "# Eliminar las filas del DataFrame original (df)\n",
    "df = df.drop(index=indices_a_eliminar)\n",
    "dataToken = dataToken.drop(index=indices_a_eliminar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "gh78itlKXa6k"
   },
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "dataToken = df.copy()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "LO8o9oXfXUGN",
    "outputId": "984d5710-c71c-443c-c5bc-7ea926a2a39b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acabo de ver la gran p√©rdida que estamos tenie...</td>\n",
       "      <td>tristeza</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¬øA que vamos a reconstruir Notre Dame antes de...</td>\n",
       "      <td>tristeza</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desde ayer andan sufriendo por el incendio y n...</td>\n",
       "      <td>ira</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muy afectada como much√≠sima gente por lo ocurr...</td>\n",
       "      <td>tristeza</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es una mierda lo que paso pero please dejen de...</td>\n",
       "      <td>disgusto</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7566</th>\n",
       "      <td>Dembele de mierda piernas chuecas regalaste do...</td>\n",
       "      <td>ira</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7567</th>\n",
       "      <td>Dembele es un imb√©cil, neta es incre√≠ble lo pe...</td>\n",
       "      <td>ira</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7568</th>\n",
       "      <td>Puta q son desagradables los wnes del Barca en...</td>\n",
       "      <td>ira</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7569</th>\n",
       "      <td>Como te odio , odio tus comentarios filos√≥fico...</td>\n",
       "      <td>ira</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7570</th>\n",
       "      <td>Miedo me da que mi pa√≠s est√© en manos de perso...</td>\n",
       "      <td>miedo</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7571 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text   emotion  token_count\n",
       "0     Acabo de ver la gran p√©rdida que estamos tenie...  tristeza           27\n",
       "1     ¬øA que vamos a reconstruir Notre Dame antes de...  tristeza           20\n",
       "2     Desde ayer andan sufriendo por el incendio y n...       ira           16\n",
       "3     Muy afectada como much√≠sima gente por lo ocurr...  tristeza           40\n",
       "4     Es una mierda lo que paso pero please dejen de...  disgusto           13\n",
       "...                                                 ...       ...          ...\n",
       "7566  Dembele de mierda piernas chuecas regalaste do...       ira           13\n",
       "7567  Dembele es un imb√©cil, neta es incre√≠ble lo pe...       ira           11\n",
       "7568  Puta q son desagradables los wnes del Barca en...       ira           13\n",
       "7569  Como te odio , odio tus comentarios filos√≥fico...       ira           29\n",
       "7570  Miedo me da que mi pa√≠s est√© en manos de perso...     miedo           14\n",
       "\n",
       "[7571 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicar la funci√≥n y filtrar las filas con menos de 10 tokens\n",
    "dataToken['token_count'] = dataToken['text'].apply(contar_tokens_simple)\n",
    "# dataToken = dataToken[dataToken['token_count'] <= 7]\n",
    "\n",
    "# Mostrar el resultado\n",
    "dataToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dtale.show(dataToken)\n",
    "d.open_browser() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "neutral     3877\n",
       "alegr√≠a     1678\n",
       "tristeza     979\n",
       "ira          797\n",
       "disgusto     153\n",
       "miedo         87\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acabo de ver la gran p√©rdida que estamos tenie...</td>\n",
       "      <td>tristeza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¬øA que vamos a reconstruir Notre Dame antes de...</td>\n",
       "      <td>tristeza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desde ayer andan sufriendo por el incendio y n...</td>\n",
       "      <td>ira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muy afectada como much√≠sima gente por lo ocurr...</td>\n",
       "      <td>tristeza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Es una mierda lo que paso pero please dejen de...</td>\n",
       "      <td>disgusto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7566</th>\n",
       "      <td>Dembele de mierda piernas chuecas regalaste do...</td>\n",
       "      <td>ira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7567</th>\n",
       "      <td>Dembele es un imb√©cil, neta es incre√≠ble lo pe...</td>\n",
       "      <td>ira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7568</th>\n",
       "      <td>Puta q son desagradables los wnes del Barca en...</td>\n",
       "      <td>ira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7569</th>\n",
       "      <td>Como te odio , odio tus comentarios filos√≥fico...</td>\n",
       "      <td>ira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7570</th>\n",
       "      <td>Miedo me da que mi pa√≠s est√© en manos de perso...</td>\n",
       "      <td>miedo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7571 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text   emotion\n",
       "0     Acabo de ver la gran p√©rdida que estamos tenie...  tristeza\n",
       "1     ¬øA que vamos a reconstruir Notre Dame antes de...  tristeza\n",
       "2     Desde ayer andan sufriendo por el incendio y n...       ira\n",
       "3     Muy afectada como much√≠sima gente por lo ocurr...  tristeza\n",
       "4     Es una mierda lo que paso pero please dejen de...  disgusto\n",
       "...                                                 ...       ...\n",
       "7566  Dembele de mierda piernas chuecas regalaste do...       ira\n",
       "7567  Dembele es un imb√©cil, neta es incre√≠ble lo pe...       ira\n",
       "7568  Puta q son desagradables los wnes del Barca en...       ira\n",
       "7569  Como te odio , odio tus comentarios filos√≥fico...       ira\n",
       "7570  Miedo me da que mi pa√≠s est√© en manos de perso...     miedo\n",
       "\n",
       "[7571 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dtale.show(df)\n",
    "d.open_browser() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# df = pd.read_csv('../data/EMOEVENT_CLEANED_v6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar textos\n",
    "df[\"text\"] = df[\"text\"].apply(limpiar_texto)\n",
    "\n",
    "# 1. Eliminar espacio antes de coma ' ,'\n",
    "df['text'] = df['text'].str.replace(r'\\s+,', ',', regex=True)\n",
    "\n",
    "# 2. Eliminar varias comas juntas ',,,,' (todas las comas consecutivas)\n",
    "df['text'] = df['text'].str.replace(r',+', ',', regex=True)\n",
    "\n",
    "# 3. Eliminar solo el √∫ltimo punto al final si est√° solo, pero no tocar los '...'\n",
    "df['text'] = df['text'].str.replace(r'(?<!\\.\\.\\.)\\.$', '', regex=True)\n",
    "\n",
    "# 4. Eliminar el espacio antes del punto ' .'\n",
    "df['text'] = df['text'].str.replace(r'\\s+\\.', '.', regex=True)\n",
    "\n",
    "\n",
    "# 5. Eliminar el espacio antes del signo de interrogaci√≥n ' ?' y el signo de exclamaci√≥n ' !'\n",
    "df['text'] = df['text'].str.replace(r'\\s+\\?', '?', regex=True)\n",
    "df['text'] = df['text'].str.replace(r'\\s+\\!', '!', regex=True)\n",
    "\n",
    "# eliminar puntos finales\n",
    "df[\"text\"] = df[\"text\"].str.rstrip(\".\")\n",
    "\n",
    "# 6. Letras sueltas a eliminar, excluyendo conectores v√°lidos como y, o, a, e\n",
    "df['text'] = df['text'].str.replace(r'\\b[b-df-hj-np-tv-z]\\b', '', regex=True)\n",
    "\n",
    "# limpiar espacios\n",
    "df['text'] = df['text'].str.replace(r'\\s+([;:!,?.])', r'\\1', regex=True)\n",
    "\n",
    "# Limpiar textos\n",
    "df[\"text\"] = df[\"text\"].apply(limpiar_texto)\n",
    "# Eliminar espacios extra al final otra vez por seguridad\n",
    "df[\"text\"] = df[\"text\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para detectar emojis en un texto\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticonos\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # s√≠mbolos y pictogramas\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transporte y mapas\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # banderas (iOS)\n",
    "    u\"\\U00002700-\\U000027BF\"  # Dingbats\n",
    "    u\"\\U0001F900-\\U0001F9FF\"  # s√≠mbolos suplementarios\n",
    "    u\"\\U00002600-\\U000026FF\"  # Miscel√°nea\n",
    "    \"]+\", flags=re.UNICODE)\n",
    "# Eliminar filas donde emotion es 'neutral' y el texto contiene al menos un emoji\n",
    "df = df[~((df['emotion'] == 'neutral') & (df['text'].str.contains(emoji_pattern)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/EMOEVENT_CLEANED_v10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import dtale\n",
    "# # Mostrar el DataFrame en D-Tale\n",
    "# d = dtale.show(df)\n",
    "# d.open_browser() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 23:11:50,988 - ERROR    - Exception occurred while processing request: object of type 'NoneType' has no len()\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\leo23\\OneDrive\\Documentos\\Fine_tuning_llama2\\venv\\Lib\\site-packages\\dtale\\views.py\", line 120, in _handle_exceptions\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\leo23\\OneDrive\\Documentos\\Fine_tuning_llama2\\venv\\Lib\\site-packages\\dtale\\views.py\", line 1595, in get_processes\n",
      "    [_load_process(data_id) for data_id in global_state.keys()],\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\leo23\\OneDrive\\Documentos\\Fine_tuning_llama2\\venv\\Lib\\site-packages\\dtale\\views.py\", line 1595, in <listcomp>\n",
      "    [_load_process(data_id) for data_id in global_state.keys()],\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\leo23\\OneDrive\\Documentos\\Fine_tuning_llama2\\venv\\Lib\\site-packages\\dtale\\views.py\", line 1580, in _load_process\n",
      "    rows=len(data),\n",
      "         ^^^^^^^^^\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "2025-04-29 23:11:55,553 - INFO     - Executing shutdown...\n",
      "2025-04-29 23:11:55,553 - INFO     - Not running with the Werkzeug Server, exiting by searching gc for BaseWSGIServer\n",
      "2025-04-29 23:11:55,641 - ERROR    - weakly-referenced object no longer exists\n",
      "2025-04-29 23:11:55,643 - ERROR    - weakly-referenced object no longer exists\n",
      "C:\\Users\\leo23\\OneDrive\\Documentos\\Fine_tuning_llama2\\venv\\Lib\\site-packages\\dtale\\app.py:445: FutureWarning:\n",
      "\n",
      "`torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "\n",
      "2025-04-29 23:11:55,673 - ERROR    - weakly-referenced object no longer exists\n",
      "2025-04-29 23:11:55,674 - ERROR    - weakly-referenced object no longer exists\n"
     ]
    }
   ],
   "source": [
    "# # --------------------------------------------------------\n",
    "# # 2. Cargar modelo y tokenizador\n",
    "# # --------------------------------------------------------\n",
    "# from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# model_name = \"mrm8488/bert-spanish-cased-finetuned-ner\"  #\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForTokenClassification.from_pretrained(model_name).to(\"cuda\" or \"cpu\")\n",
    "\n",
    "# # --------------------------------------------------------\n",
    "# # 3. Funci√≥n optimizada para detecci√≥n de errores (batch)\n",
    "# # --------------------------------------------------------\n",
    "# def detectar_errores_lote(textos, batch_size=16):\n",
    "#     errores_totales = []\n",
    "    \n",
    "#     # Procesar en lotes para mayor eficiencia\n",
    "#     for i in tqdm(range(0, len(textos), batch_size), desc=\"Procesando textos\"):\n",
    "#         batch = textos[i:i+batch_size]\n",
    "        \n",
    "#         # Tokenizar y enviar a GPU\n",
    "#         inputs = tokenizer(\n",
    "#             batch,\n",
    "#             padding=True,\n",
    "#             truncation=True,\n",
    "#             return_tensors=\"pt\"\n",
    "#         ).to(device)\n",
    "        \n",
    "#         # Inferencia\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(**inputs)\n",
    "        \n",
    "#         # Decodificar resultados\n",
    "#         predictions = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "        \n",
    "#         # Procesar cada texto del lote\n",
    "#         for j in range(len(batch)):\n",
    "#             tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][j])\n",
    "#             errores = [\n",
    "#                 token.replace(\"##\", \"\") \n",
    "#                 for token, pred in zip(tokens, predictions[j]) \n",
    "#                 if token not in [\"[CLS]\", \"[SEP]\"] and pred == 1\n",
    "#             ]\n",
    "#             errores_totales.append(errores)\n",
    "    \n",
    "#     return errores_totales\n",
    "\n",
    "# # --------------------------------------------------------\n",
    "# # 4. Aplicar al DataFrame\n",
    "# # --------------------------------------------------------\n",
    "# # Convertir la columna 'text' a lista\n",
    "# textos = df[\"text\"].tolist()\n",
    "\n",
    "# # Procesar en lotes usando GPU\n",
    "# df[\"errores_bert\"] = detectar_errores_lote(textos, batch_size=16)\n",
    "\n",
    "# # Mostrar resultados\n",
    "# print(df[[\"text\", \"errores_bert\"]].head())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
